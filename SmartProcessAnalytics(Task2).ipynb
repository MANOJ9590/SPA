{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SmartProcessAnalytics(Task2).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP76gmhYKNeZRtNtnvkEXWh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MANOJ9590/SPA/blob/main/SmartProcessAnalytics(Task2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2 - Predictive Analysis based on the event log\n",
        "\n",
        "---\n",
        "Group 12\n",
        "\n",
        "*   Venkatesh Hariharapura Shivashankar - 220200713\n",
        "*   Vibha lyer - 220200717\n",
        "*   Manojkumar Krishnakumar - 220200906\n",
        "*   Priya Yadav - 220200937\n",
        "*   Ramesh Reddy Modulla - 221100615"
      ],
      "metadata": {
        "id": "dc1puGt0nQHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pm4py"
      ],
      "metadata": {
        "id": "477QxO6enPXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pm4py\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "lPw6YsL3ZX-f"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7HNCr-OZaXT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def import_xes(filepath):\n",
        "  return pm4py.read_xes(filepath)"
      ],
      "metadata": {
        "id": "usK39ppyZ8gv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def events_to_cases(eventlog):\n",
        "  case={}\n",
        "  complete_events = []\n",
        "  for concept in range(0,len(eventlog)) :\n",
        "    events = []\n",
        "    for name in range(0 ,len(eventlog[concept])):\n",
        "      events.append(eventlog[concept][name]['concept:name'])\n",
        "      complete_events.append(eventlog[concept][name]['concept:name'])\n",
        "      case[concept] = events\n",
        "  return case,complete_events"
      ],
      "metadata": {
        "id": "vfEb-T2sbSwI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def runing_instance_sublist_check(Ngram_sequence,trace):\n",
        "    for i in range(len(trace) - len(Ngram_sequence) + 1):\n",
        "      if ((Ngram_sequence) == (trace[i:i+len(Ngram_sequence)])): return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "oYqzU7ijfRjg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def computing_probabilites(events_log, n_th_gram, running_instance):\n",
        "  if (n_th_gram <= len(running_instance)):\n",
        "    predections=[]\n",
        "    incremental_predection_probability={}\n",
        "    for i in range(n_th_gram):\n",
        "      if(n_th_gram >=1):\n",
        "        Ngram_seq = running_instance[-n_th_gram : ]\n",
        "        n_th_element = Ngram_seq[len(Ngram_seq)-1]\n",
        "        for j in range(len(events_log)):\n",
        "          if(runing_instance_sublist_check(Ngram_seq,events_log[j])==True):\n",
        "            next_event=(events_log[j].index(n_th_element)+1)\n",
        "            if(len(events_log[j]) == next_event):\n",
        "              continue\n",
        "            predection = events_log[j][next_event]\n",
        "            predections.append(predection)\n",
        "        max_occurance = max(predections, key = predections.count)\n",
        "        occurance = dict((element,predections.count(element)) for element in set(predections))\n",
        "        probabilities = {}\n",
        "        for k, v in occurance.items():\n",
        "          probabilities[k] = round(v /sum(occurance.values()),4)\n",
        "      incremental_predection_probability[str(n_th_gram) + \"- Gram\"] = probabilities\n",
        "      n_th_gram -= 1\n",
        "    return pd.DataFrame(incremental_predection_probability).fillna(0)\n",
        "  else : \n",
        "    print(\"range of Ngram value should be less or equal to number of events in running instance input provided\")"
      ],
      "metadata": {
        "id": "t4HQxIbvgXxA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cases,Total_events=events_to_cases(import_xes('/content/drive/MyDrive/BPIChallenge2018.xes'))"
      ],
      "metadata": {
        "id": "ygXW-xQ1Jf-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "#insert any number between 1 to 14424 to get the sequece to design the running sequence in the next step \n",
        "print(yaml.dump(cases[23]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKws5KaDj8b5",
        "outputId": "5916d034-8dd1-49af-f605-88c12c057aae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[mail valid, initialize, begin editing, finish pre-check, finish editing, initialize,\n",
            "  begin editing, finish editing, finish editing, create, mail income, begin editing,\n",
            "  begin editing, finish pre-check, finish editing, create, begin editing, begin editing,\n",
            "  finish pre-check, finish editing, create, initialize, performed, initialize, begin\n",
            "    editing, calculate, finish editing, begin editing, calculate, finish editing,\n",
            "  begin editing, calculate, finish editing, begin editing, calculate, finish editing,\n",
            "  begin editing, calculate, finish editing, begin editing, calculate, finish editing,\n",
            "  begin editing, calculate, finish editing, begin editing, calculate, finish editing,\n",
            "  begin editing, calculate, calculate, finish editing, decide, begin payment, insert\n",
            "    document, insert document, finish payment]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "running_process_instance = ['finish editing', 'create', 'initialize', 'performed']\n",
        "# enter the number less than or equal to nuber of event sin runnning instance input provided\n",
        "Ngram_input = 4\n",
        "print(\"Dataset contains\",str(len(Total_events)), \"events suming to\", str(len(cases)) ,\"cases\\n\",)\n",
        "print('\\033[1m'+\"Predective Analysis \\n\")\n",
        "print(computing_probabilites(cases,Ngram_input,running_process_instance).to_markdown(tablefmt=\"grid\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VEmspaLaNOF",
        "outputId": "5916e46c-bfad-4872-deaf-d9e63d682dce"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset contains 847383 events suming to 14424 cases\n",
            "\n",
            "\u001b[1mPredective Analysis \n",
            "\n",
            "+------------------------+-----------+-----------+-----------+-----------+\n",
            "|                        |   4- Gram |   3- Gram |   2- Gram |   1- Gram |\n",
            "+========================+===========+===========+===========+===========+\n",
            "| calculate              |    0.0003 |    0.0008 |    0.0027 |    0.0033 |\n",
            "+------------------------+-----------+-----------+-----------+-----------+\n",
            "| change department      |    0.0002 |    0.0002 |    0.0001 |    0.0001 |\n",
            "+------------------------+-----------+-----------+-----------+-----------+\n",
            "| plan                   |    0.0002 |    0.0002 |    0.0002 |    0.0001 |\n",
            "+------------------------+-----------+-----------+-----------+-----------+\n",
            "| finish editing         |    0.0009 |    0.0015 |    0.0048 |    0.0058 |\n",
            "+------------------------+-----------+-----------+-----------+-----------+\n",
            "| finish preparations    |    0.0002 |    0.0002 |    0.0027 |    0.0034 |\n",
            "+------------------------+-----------+-----------+-----------+-----------+\n",
            "| insert document        |    0.0012 |    0.0016 |    0.0035 |    0.004  |\n",
            "+------------------------+-----------+-----------+-----------+-----------+\n",
            "| save                   |    0.0022 |    0.0031 |    0.0346 |    0.0437 |\n",
            "+------------------------+-----------+-----------+-----------+-----------+\n",
            "| mail income            |    0.0003 |    0.0003 |    0.0008 |    0.001  |\n",
            "+------------------------+-----------+-----------+-----------+-----------+\n",
            "| initialize             |    0.9468 |    0.944  |    0.8859 |    0.8691 |\n",
            "+------------------------+-----------+-----------+-----------+-----------+\n",
            "| begin editing          |    0.0477 |    0.048  |    0.0638 |    0.0684 |\n",
            "+------------------------+-----------+-----------+-----------+-----------+\n",
            "| prepare offline        |    0      |    0      |    0.0005 |    0.0006 |\n",
            "+------------------------+-----------+-----------+-----------+-----------+\n",
            "| take original document |    0      |    0      |    0      |    0      |\n",
            "+------------------------+-----------+-----------+-----------+-----------+\n",
            "| cancel offline         |    0      |    0      |    0.0001 |    0.0001 |\n",
            "+------------------------+-----------+-----------+-----------+-----------+\n",
            "| finish pre-check       |    0      |    0      |    0.0002 |    0.0003 |\n",
            "+------------------------+-----------+-----------+-----------+-----------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "F2ZkT0RGrwva"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}